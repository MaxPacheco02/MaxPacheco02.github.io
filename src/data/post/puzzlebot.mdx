---
publishDate: 2024-04-11T00:00:00Z
updateDate: 2024-06-11T00:00:00Z
id: e40
author: Max Pacheco
title: “Puzzlebot” Differential Car Driving on a Scaled Track with Traffic Elements
# excerpt:
image: ~/assets/images/puzzlebot.png
category: Class Project
tags:
  - ROS 2
  - CPP
  - Python
  - Nvidia Jetson
metadata:
  canonical: https://astrowind.vercel.app/get-started-website-with-astro-tailwind-css
---

import Logo from '~/components/Logo.astro';

import { YouTube, Tweet, Vimeo, LinkPreview } from 'astro-embed';
import CenteredImage from '~/components/common/CenteredImage.astro';
import Image from '~/components/common/Image.astro';
import ImageGrid from '~/components/common/ImageGrid.astro';
import VideoGrid from '~/components/common/VideoGrid.astro';

For this group class project, we used the Puzzlebot kit from Manchester Robotics containing a differential car kit consisting of a 2-level modular base for computer boards and two DC motors with wheels attached, a “Hackerboard” chip which dealt with the speed control for each wheel, and a camera used for traffic signal detections.

<YouTube id="PcHiRVuE7HE" />

I developed the control package in ROS2 using C++ nodes, based on 3 main nodes: pose estimation, a guidance node, and a waypoint publisher. The pose estimation listens to the angular velocity of each wheel, which updates the dynamic model’s variables, which is the vehicle’s 2D pose (position and orientation measured from where the vehicle started).

<CenteredImage src="~/assets/images/pzb0.gif" alt="pzb gif" />

On the other hand, the waypoint publisher takes into consideration that pose and the context of what the camera is identifying (just a line to follow, or if the vehicle is in front of a traffic signal), and based on that the algorithm either makes corrections as a local planner for path following, or generates a set of waypoints for the car to follow. This turned out to be very useful, because as long as the vehicle followed the waypoint, it didn’t need to listen to what the camera was detecting, and that was useful when “crossing roads” (dotted lines which could confuse the line follower algorithm) or turning left of right (there were moments were the region of interest of the camera focused on the lower pixels wouldn’t show a line to follow, so the car could get lost there if pure line following was always enabled). Finally, the guidance node is based on a simple pure pursuit algorithm controlling the heading references with a PID controller for a smoother approach to the line.

<CenteredImage src="~/assets/images/pzb3.gif" alt="pzb gif3" />

I also worked on the optimization of the line follower algorithm, migrating the code from python to C++, and collaborated in the change of the camera messages from sensor_msgs/Image to CompressedImage messages, which made the topic transmission way faster and gave us the chance to increase our vehicle’s speed.

<CenteredImage src="~/assets/images/pzb1.gif" alt="pzb gif" width="500%" />

As a bonus, inspired by the [Boat project](/usv), I worked on a master node, which enabled the toggling between a teleoperated mode and an autonomous mode. That made testing easier and faster, because if I saw the car deviate, or the YOLO algorithm ignored a traffic signal, I could always toggle the modes and go back to where the car failed, and debug errors faster.

<CenteredImage src="~/assets/images/pzb2.gif" alt="pzb gif" width="500%" />

In the end, I am very proud to say our team had the fastest car (and by a lot) and could correctly follow all the traffic signals without the intervention of a person for aiding, but most importantly, I really enjoyed the process of building a new ROS2 project from scratch and discussing with my teammates different approaches, and testing all the different ideas that occurred to us.

## Check out the repository!

<LinkPreview id="https://github.com/MaxPacheco02/TurboPlusPlus_ImplementacionRobotica" />
